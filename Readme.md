This program was written as part of a project to understand LLMs. In the process of writing the code, three LLMs were run on my hardware and asked improving questions about the same source code file so they could expand upon it. Meta's llama3.1-7B, Google's Gemma2-2B, and IBM's Granite-Code-3B. All open source models, running on local Linux hardware.

With gradual prompting they were successful in building a decent application, when guided by a human who could decide how best to implement individual features. Code that was written usual worked, but they would often skip parts of the implementation and refuse to go over them. Passing the code file consecutively between models often helped with gap filling, but in the end this won't work unless you can read and write your own code anywhere that it may be required, or choose a more efficient method to execute a task.